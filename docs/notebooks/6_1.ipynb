{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradient descent exercises.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO_FPQCUnHnX"
      },
      "source": [
        "# Gradient descent introduction\n",
        "[Hobbit village](https://courses.cs.ut.ee/MTAT.03.227/2015_spring/uploads/Main/home-exercises-5.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "UYn1MBDT1vUr"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "import copy\n",
        "sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "nNqH83Jz1vUs"
      },
      "source": [
        "Below one can find function plotting the village"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "WzZzisMR1vUs"
      },
      "source": [
        "def plot_village(coordinates, l=1):\n",
        "    # Checking, that all the coordinates are less than l\n",
        "    assert (coordinates <= l).all(), 'All the houses should be in a village'\n",
        "    \n",
        "    # Draw horizontal line\n",
        "    plt.hlines(0, 0, l)\n",
        "    plt.xlim(0, l)\n",
        "    plt.ylim(-0.5, 0.5)\n",
        "    \n",
        "    # Draw house points\n",
        "    y = np.zeros(np.shape(coordinates))\n",
        "    plt.title('The Hobbit Village')\n",
        "    plt.plot(coordinates,y,'o',ms = 10)\n",
        "    plt.axis('off')\n",
        "    plt.xlabel('Coordinates')\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(15, 1)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "acc8i4yg1vUt",
        "outputId": "b46c176a-5210-427e-a109-430147ba472f"
      },
      "source": [
        "N = 25\n",
        "l = 1\n",
        "x = np.random.rand(N)*l\n",
        "    \n",
        "plot_village(x, l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6MxKTnnDXi0"
      },
      "source": [
        "The inhabitants of a one-dimensional village want to connect to the Internet, so they need a central service station from which a cable will stretch to all the houses in the village. Let the price of the cable to be pulled from the station to each house independently be determined by some function p(d) . Then it is clear that the village will have to pay the following amount for access to the World Wide Web:\n",
        "$$\n",
        "P(w, x) = \\sum\\limits_{i=1}^N p(d_i) = \\sum\\limits_{i=1}^N p(|w - x_i|)\n",
        "$$\n",
        "$w$ - station location, $x_i$ - location of $i$ house."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "sO3lhbym1vUv"
      },
      "source": [
        "Write analytical solution $w^*$ for minimization $P(w,x)$, if $p(d) = d^2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUZmjMHILjvm"
      },
      "source": [
        "<font color=\"lime\"> ==YOUR ANSWER== </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "Q84chDrl1vUv"
      },
      "source": [
        "Write loss function $P(x,w)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "PPwj7e2h1vUw"
      },
      "source": [
        "def P(w, x):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "TefzahWd1vUw"
      },
      "source": [
        "Plot loss function on the range $(0, l)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "MZiksa8J1vUw"
      },
      "source": [
        "### YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "R5fZ71TR1vUx"
      },
      "source": [
        "Write gradient of loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "rRFYdfr11vUx"
      },
      "source": [
        "def dP(w, x):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "pj8be_b61vUx"
      },
      "source": [
        "Plot gradient of loss function on the range $(0,l)$. Which point on the graph is of particular interest? Why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "XYme7fvi1vUy"
      },
      "source": [
        "### YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "gj3XxPXA1vUy"
      },
      "source": [
        "Write function `gradient_descent`, which returns $w_k$ after a fixed number of steps.   \n",
        "\n",
        "$$\n",
        "w_{k+1} = w_k - \\mu \\nabla P(w_k)\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "18oj4Hp21vUz"
      },
      "source": [
        "def gradient_descent(x, dP, w0, mu, Nsteps):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "HqLslJrc1vUz"
      },
      "source": [
        "Modify `gradient_descent` to return all optimization trajectory $(w_0, w_1, \\ldots, w_k)$.\n",
        "Plot loss function trajectory (Y axis - $f(w_k)$); X axis - $k$) for initial point $w_0 = 0.01, 0.1, 0.15, 0.19, 0.20, 0.21$.   \n",
        "Draw conclusions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "weQpMijs1vUz"
      },
      "source": [
        "def gradient_descent(x, dP, w0, mu, Nsteps):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "AyyKSi261vU9"
      },
      "source": [
        "The village decided to lay cable using new technology. That's why the price of the cable changed to:\n",
        "\n",
        "$$\n",
        "p(d) = |d|\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "1IzutLPd1vU9"
      },
      "source": [
        "Write new function `P`, `dP`. Plot graphs for various $x$ and $w$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "CYPjm99M1vU-"
      },
      "source": [
        "def P(w, x):\n",
        "    pass\n",
        "    \n",
        "def dP(w, x):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "6QylDK9H1vU_"
      },
      "source": [
        "Write new analytical solytion $w^*$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHufSF8J1FJH"
      },
      "source": [
        "<font color=\"lime\"> ==YOUR ANSWER== </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "2AH3s2m-1vU_"
      },
      "source": [
        "Plot loss trajectory for new $p(d)$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLXXZX3K2hgR"
      },
      "source": [
        "### YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Gq7gvrr2tll"
      },
      "source": [
        "After several years, the goverment propose to destroy the first station but choose locations for two new stations. In this conditions cost of connecting all house calculated by new formula:\n",
        "\n",
        "$$\n",
        "P(w_1, w_2, x) = \\sum\\limits_{i=1}^N p(d_i) = \\sum\\limits_{i=1}^N p\\left(\\min\\left(\\left|w_1 - x_i\\right|, \\left|w_2 - x_i\\right|\\right)\\right)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "S5lTHBxZ1vVE"
      },
      "source": [
        "Write new `P`, `dP`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "-5Qza4zJ1vVE"
      },
      "source": [
        "def P(w1, w2, x):\n",
        "    pass\n",
        "\n",
        "def dP(w1, w2, x):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "cjuu4XWd1vVE"
      },
      "source": [
        "Plot  $P(w_1, w_2), \\|\\nabla P(w_1, w_2)\\|$ for different number of houses $N$. Comment on what happens as you increase $N$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWbKLR8Br-yq"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "np.random.seed(10)\n",
        "Ns = [10, 50, 500, 5000]\n",
        "l = 1\n",
        "for N in Ns:\n",
        "    x = np.random.rand(N)*l\n",
        "    w1 = np.linspace(0,l,200)\n",
        "    w2 = np.linspace(0,l,200)\n",
        "\n",
        "    p = np.zeros([w1.shape[0], w1.shape[0]])\n",
        "    dp = np.zeros([w1.shape[0], w1.shape[0]])\n",
        "    i = 0\n",
        "    for w1_ in w1:\n",
        "        j = 0\n",
        "        for w2_ in w2:\n",
        "            p[i][j] = P(w1_, w2_, x)\n",
        "            dp[i][j] = np.linalg.norm(dP(w1_, w2_, x))\n",
        "            j += 1\n",
        "        i += 1\n",
        "    f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
        "    c1 = ax1.contourf(w1, w2, p, cmap=\"viridis\")\n",
        "    plt.colorbar(c1, ax = ax1)\n",
        "    ax1.set_title('P')\n",
        "    c2 = ax2.contourf(w1, w2, dp, cmap=\"viridis\")\n",
        "    plt.colorbar(c2, ax = ax2)\n",
        "    ax2.set_title('dP')\n",
        "    f.set_size_inches(12, 5)\n",
        "    f.suptitle('2 routers, $N = $'+str(N), fontsize=26)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "XA1wa7pm1vVG"
      },
      "source": [
        "Write new `gradient_descent`, which returns the entire optimization trajectory $(w_k)$ after a fixed number of steps and draws the process on the graph $P(w_1, w_2)$ or $\\|\\nabla P (w_1, w_2)\\|$ that were above. To ease visualization try to use `ax.quiver`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "o7gHgwXW1vVG"
      },
      "source": [
        "def gradient_descent(P, dP, w0, mu, Nsteps, plot = False):\n",
        "    trajectory = [w0]\n",
        "    ###\n",
        "    ### Your code\n",
        "    ###\n",
        "    if plot:\n",
        "        w1 = np.linspace(0,l,50)\n",
        "        w2 = np.linspace(0,l,50)\n",
        "        p = np.zeros([w1.shape[0], w1.shape[0]])\n",
        "\n",
        "        i = 0\n",
        "        for w1_ in w1:\n",
        "            j = 0\n",
        "            for w2_ in w2:\n",
        "                p[i][j] = P(w1_, w2_, x)\n",
        "                j += 1\n",
        "            i += 1\n",
        "\n",
        "        plt.figure(figsize=(11,11))\n",
        "        plt.title('Gradient descent path ($\\mu=$'+str(mu)+', $N=$'+str(N)+')', fontsize=26)\n",
        "        plt.xlabel('$w_1$', fontsize=22)\n",
        "        plt.ylabel('$w_2$', fontsize=22)\n",
        "        plt.xticks(fontsize=18)\n",
        "        plt.yticks(fontsize=18)\n",
        "        plt.xlim(-0.01,1.01)\n",
        "        plt.ylim(-0.01,1.01)\n",
        "        plt.contourf(w1, w2, p, cmap='viridis')\n",
        "        plt.colorbar()\n",
        "\n",
        "        w1s = [w[0] for w in trajectory]\n",
        "        w2s = [w[1] for w in trajectory]\n",
        "        plt.scatter(w1s, w2s, color='orange')\n",
        "        plt.plot(w1s, w2s, color='red')\n",
        "\n",
        "        plt.show()\n",
        "    return trajectory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNtBGTwD5L6e"
      },
      "source": [
        "### YOUR CODE\n",
        "N = 2\n",
        "x = np.random.rand(N)*l\n",
        "gradient_descent(P, dP, (0.04,0.02), 0.001, 100, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu-80dz9tqEb"
      },
      "source": [
        "# Extra: projected gradient descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "G48L7NiY1vVK"
      },
      "source": [
        "Construction is almost underway, but new safety regulations do not allow stations to be on the distance more than 1/2:\n",
        " \n",
        "$$\n",
        "\\left|w_1 - w_2\\right| \\leq \\dfrac{l}{2}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "kLB7Dtkn1vVK"
      },
      "source": [
        "Plot our feasible set. Is it convex?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BzpO6Mw5fJz"
      },
      "source": [
        "### YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "zlXbM7681vVL"
      },
      "source": [
        "Write `projected_SGD`, which returns the entire optimization trajectory $(w_k)$ after a fixed number of steps and draws the process on the graphs $P$ and $\\nabla P$ that were above.\n",
        "\n",
        "The projected gradient descent method consists in making a gradient step and then checking if the obtained point belongs to the feasible set. If it belongs to the target set, the algorithm continues, otherwise a projection to the feasible set is made."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t89_1H4b1vVL"
      },
      "source": [
        "def conditional_SGD(x, dP_sigma, w0, mu, Nsteps, p=0.4):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWFxsiwV1vVL"
      },
      "source": [
        "def projection(w):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIC7fCJk7O_l"
      },
      "source": [
        "### YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw7ELccWWkve"
      },
      "source": [
        "# Steepest gradient descent for hyperparameter search in Machine Learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n7dLe9hZGcI"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIuAgcnFjM2y",
        "outputId": "fc72a508-6a31-4998-ff6c-4463b8ac471e"
      },
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                16010     \n",
            "=================================================================\n",
            "Total params: 34,826\n",
            "Trainable params: 34,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R7mWouzjUch",
        "outputId": "cfb9900a-0222-47b3-c24a-2f43ff15fb98"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "422/422 [==============================] - 34s 5ms/step - loss: 0.3713 - accuracy: 0.8880 - val_loss: 0.0874 - val_accuracy: 0.9767\n",
            "Epoch 2/15\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1132 - accuracy: 0.9652 - val_loss: 0.0632 - val_accuracy: 0.9835\n",
            "Epoch 3/15\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0854 - accuracy: 0.9734 - val_loss: 0.0507 - val_accuracy: 0.9863\n",
            "Epoch 4/15\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0706 - accuracy: 0.9777 - val_loss: 0.0493 - val_accuracy: 0.9865\n",
            "Epoch 5/15\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0622 - accuracy: 0.9809 - val_loss: 0.0417 - val_accuracy: 0.9873\n",
            "Epoch 6/15\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0577 - accuracy: 0.9825 - val_loss: 0.0379 - val_accuracy: 0.9888\n",
            "Epoch 7/15\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0511 - accuracy: 0.9845 - val_loss: 0.0361 - val_accuracy: 0.9900\n",
            "Epoch 8/15\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0470 - accuracy: 0.9851 - val_loss: 0.0345 - val_accuracy: 0.9907\n",
            "Epoch 9/15\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0449 - accuracy: 0.9864 - val_loss: 0.0327 - val_accuracy: 0.9898\n",
            "Epoch 10/15\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0424 - accuracy: 0.9863 - val_loss: 0.0323 - val_accuracy: 0.9915\n",
            "Epoch 11/15\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0402 - accuracy: 0.9871 - val_loss: 0.0303 - val_accuracy: 0.9918\n",
            "Epoch 12/15\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0356 - accuracy: 0.9886 - val_loss: 0.0301 - val_accuracy: 0.9920\n",
            "Epoch 13/15\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0365 - accuracy: 0.9882 - val_loss: 0.0294 - val_accuracy: 0.9920\n",
            "Epoch 14/15\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0349 - accuracy: 0.9891 - val_loss: 0.0302 - val_accuracy: 0.9908\n",
            "Epoch 15/15\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0339 - accuracy: 0.9890 - val_loss: 0.0285 - val_accuracy: 0.9915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f04b04cbe50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep6DYzEzjXYn",
        "outputId": "cb57540d-3929-46ad-cdc4-b782373b0813"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.02343994379043579\n",
            "Test accuracy: 0.9918000102043152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPmBU23qoJt_"
      },
      "source": [
        "In this task you are to select any **single hyperparameter** (batchsize, learning rate, number of layers, number of neurons in a specific layer, dropout rate etc.) and any metric you want to maximize\\minimize.\n",
        "\n",
        "Use `minimize_scalar` from scipy to solve this task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR0gSCn7kJ-j"
      },
      "source": [
        "def your_metric(hyperparameter):\n",
        "    ###\n",
        "    ### YOUR CODE\n",
        "    ###\n",
        "    return your_metric\n",
        "\n",
        "from scipy.optimize import minimize_scalar\n",
        "res = minimize_scalar(your_metric, bounds=(2, 256), method='bounded')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}